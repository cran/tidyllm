% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api_functions.R
\name{ollama}
\alias{ollama}
\title{Send LLMMessage to ollama API}
\usage{
ollama(
  .llm,
  .model = "llama3",
  .stream = FALSE,
  .seed = NULL,
  .json = FALSE,
  .temperature = NULL,
  .num_ctx = 2048,
  .ollama_server = "http://localhost:11434",
  .timeout = 120
)
}
\arguments{
\item{.llm}{An existing LLMMessage object or an initial text prompt.}

\item{.model}{The model identifier (default: "llama3").}

\item{.stream}{Should the answer be streamed to console as it comes (optional)}

\item{.seed}{Which seed should be used for random numbers  (optional).}

\item{.json}{Should output be structured as JSON  (default: FALSE).}

\item{.temperature}{Control for randomness in response generation (optional).}

\item{.num_ctx}{The size of the context window in tokens (optional)}

\item{.ollama_server}{The URL of the ollama server to be used}

\item{.timeout}{When should our connection time out}
}
\value{
Returns an updated LLMMessage object.
}
\description{
Send LLMMessage to ollama API
}
